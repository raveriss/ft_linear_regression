# ft_linear_regression 

<div align="center">

![License](https://img.shields.io/github/license/raveriss/ft_linear_regression)
![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)
[![CI](https://github.com/raveriss/ft_linear_regression/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/raveriss/ft_linear_regression/actions)
[![Coverage](https://codecov.io/gh/raveriss/ft_linear_regression/branch/main/graph/badge.svg)](https://codecov.io/gh/raveriss/ft_linear_regression)
[![Lint](https://img.shields.io/badge/lint-ruff%20âœ”-yellow.svg)]()
[![Typing](https://img.shields.io/badge/mypy-checked-purple.svg)]()
[![Mutation](https://img.shields.io/badge/mutmut-â‰¥90%25-orange.svg)]() 
[![Pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?label=pre--commit)]()
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)]()
[![Security](https://img.shields.io/badge/security-bandit-green.svg)]()

</div>

---
## ğŸ“‘ Table des matiÃ¨res
- [ğŸš€ Objectif du projet](#-objectif-du-projet)
- [ğŸ§° Stack technologique](#-stack-technologique)
- [âš¡ DÃ©marrage rapide](#-dÃ©marrage-rapide)
- [ğŸ› ï¸ Commandes Make](#-commandes-make)
- [ğŸ§ª ProcÃ©dure de soutenance](#-procÃ©dure-de-soutenance-e2e-dÃ©fense-proof)
- [ğŸ“¦ Utilisation](#-utilisation)
- [ğŸ“ DonnÃ©es](#-donnÃ©es)
- [ğŸ§  Architecture](#-architecture)
- [ğŸ› ï¸ Fichiers de configuration](#fichiers-de-configuration)
- [ğŸ§ª Tests](#-tests)
- [ğŸ” QualitÃ© du code](#-qualitÃ©-du-code)
- [ğŸ“š Documentation liÃ©e](#-documentation-liÃ©e)
- [ğŸ›¡ï¸ Licence](#licence)

---

## ğŸš€ Objectif du projet
ImplÃ©menter **un premier algorithme de Machine Learning** : une **rÃ©gression linÃ©aire simple**.  

ğŸ‘‰ PrÃ©dire le **prix dâ€™une voiture** en fonction de son kilomÃ©trage via :  
```math
estimate_price(x) = Î¸â‚€ + Î¸â‚ * x
```


- **Deux programmes obligatoires** :  
  - `train.py` â†’ entraÃ®ne le modÃ¨le (descente de gradient, mise Ã  jour simultanÃ©e de Î¸).  
  - `predict.py` â†’ prÃ©dit un prix Ã  partir dâ€™un kilomÃ©trage (0 avant entraÃ®nement).  

ğŸ¯ ConformitÃ© stricte Ã  lâ€™Ã©noncÃ© 42 :  
- Pas de `numpy.polyfit` / `sklearn.LinearRegression`.  
- Î¸ sauvegardÃ©s entre runs dans `theta.json`.  
- PrÃ©diction = **0 avant tout entraÃ®nement**.  
- Pas de crash en soutenance.

---

## ğŸ§° Stack technologique
- **Python** : 3.10.18 (Ubuntu 22.04.5 Jammy)  
- **Gestion dÃ©pendances** : [Poetry](https://python-poetry.org/)  
- **QualitÃ© / CI** : `pytest`, `coverage`, `ruff`, `mypy`, `mutmut` (mutation testing)  
- Visualisation (**bonus uniquement**) : matplotlib (installÃ© **sur demande** via `poetry install --with viz`)


---

## âš¡ DÃ©marrage rapide

> En cas dâ€™entrÃ©e invalide (ex. kilomÃ©trage nÃ©gatif ou non numÃ©rique) : le programme Ã©crit un message `ERROR: ...` sur **stderr** et quitte avec **exit 2**.


### ğŸ”§ Installation
```bash
# Avec Poetry (recommandÃ©)
poetry install --with dev
```

> â„¹ï¸ Bonus non installÃ© par dÃ©faut  
> Pour activer **uniquement** la visualisation bonus :  
> `poetry install --with viz --with dev`


### â–¶ï¸ Lancement
```bash
# EntraÃ®nement
poetry run train --data data/samples/data.csv --alpha 0.1 --iters 1000 --theta theta.json


# PrÃ©diction
poetry run predict 85000 --theta theta.json
```

> â„¹ï¸ Si la droite rouge affichÃ©e par `viz` reste quasiment horizontale, vÃ©rifiez
> le contenu de `theta.json`. Une valeur de `--alpha` trop faible (par exemple
> `1e-7`) laisse les coefficients proches de zÃ©ro. Utilisez `--alpha 0.1` (ou
> `0.01`) et suffisamment d'itÃ©rations pour obtenir une pente nÃ©gative rÃ©aliste.

## ğŸ› ï¸ Commandes Make

Les principales cibles du [Makefile](./Makefile) facilitent l'installation, la qualitÃ© du code et l'utilisation du modÃ¨leÂ :

| Commande | Description |
| --- | --- |
| `make install` | Installe les dÃ©pendances avec Poetry (groupe dev inclus). |
| `make lint` | Analyse statique du code avec Ruff. |
| `make format` | Formate le code et applique les corrections automatiques de Ruff. |
| `make type` | VÃ©rifie les types avec Mypy. |
| `make test` | Lance les tests unitaires via Pytest. |
| `make cov` | Produit les rapports de couverture (JSON, HTML, console). |
| `make mut` | ExÃ©cute les tests de mutation avec Mutmut. |
| `make train` | EntraÃ®ne le modÃ¨leÂ ; variables personnalisablesÂ : `DATA`, `ALPHA`, `ITERS`, `THETA`. |
| `make predict [km]` | PrÃ©dit le prix pour un kilomÃ©trage donnÃ©. |
| `make viz` | (Bonus) Affiche les donnÃ©es et la droite de rÃ©gression. |


## ğŸ§ª ProcÃ©dure de soutenance (E2E â€œdÃ©fense-proofâ€)

ScÃ©nario officiel Ã  dÃ©montrer en soutenance, en trois Ã©tapes **obligatoires** :

**Ã‰tape A :** prÃ©diction avant tout entraÃ®nement  
Suppression du fichier de paramÃ¨tres
```bash
rm -f theta.json
python3 -m src.predict 50000 --theta theta.json
```
â†’ RÃ©sultat attendu : 0 (Î¸â‚€=0, Î¸â‚=0 par dÃ©faut)

**Ã‰tape B :** entraÃ®nement du modÃ¨le

```bash
poetry run train --data data.csv --alpha 0.1 --iters 1000 --theta theta.json
```
â†’ Apprentissage des paramÃ¨tres Î¸â‚€ et Î¸â‚, sauvegardÃ©s dans theta.json

**Ã‰tape C :** prÃ©diction aprÃ¨s entraÃ®nement
â†’ RÃ©sultat attendu : prix non nul, cohÃ©rent avec la droite apprise (â‰ˆ CSV)
```bash
python3 -m src.predict 50000 --theta theta.json
```
âš ï¸ Ces trois Ã©tapes doivent Ãªtre **reproductibles Ã  lâ€™identique** devant le jury.
Tout Ã©cart (crash, valeur incohÃ©rente, absence de 0 en Ã©tape A, MAJ non simultanÃ©e de Î¸) = **Ã©chec en dÃ©fense.**

### (Bonus) Visualisation
> Ã‰valuable **uniquement si le mandatory est parfait**. Non requis pour la soutenance.
### Si vous avez installÃ© le groupe bonus viz :
```bash
poetry run python -m src.viz --data data.csv --theta theta.json --show-residuals
```
Ajoutez `--show-residuals` pour tracer des lignes verticales reprÃ©sentant les rÃ©sidus.
Utilisez `--sigma-k` (dÃ©faut `2`) pour colorer en orange les points dont
`|rÃ©sidu| > kÂ·Ïƒ`; ils sont ajoutÃ©s Ã  la lÃ©gende sous le nom Â«Â outliersÂ Â».
<p align="center">
  <img src="docs/price-vs-km-regression.png" alt="RÃ©gression linÃ©aire (price vs km)" width="760">
  <br><em>Nuage de points et droite Î¸â‚€ + Î¸â‚Â·x (aprÃ¨s entraÃ®nement).</em>
</p>

---

## ğŸ“¦ Utilisation
- **Mode interactif** : `predict.py` demande un kilomÃ©trage si non fourni.
    ### Exemple concret
```bash
$ make predict 
poetry run predict --theta theta.json
Enter mileage: 23000
Predicted price: 7991.88 â‚¬
```
- **End-to-End** : `predict (0)` â†’ `train` â†’ `predict â‰ˆ prix`.  

---

## ğŸ“ DonnÃ©es
- Fichier : [`data/samples/data.csv`](./data/samples/data.csv) (colonnes `km,price`).  
- HypothÃ¨ses :  
  - km â‰¥ 0  
  - valeurs numÃ©riques uniquement  
  - 24 lignes dâ€™exemple (corrÃ©lation â‰ˆ âˆ’0,86)

---

## ğŸ§  Architecture
```
.
â”œâ”€â”€ author
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ data.csv
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â””â”€â”€ src
 Â Â  â”œâ”€â”€ linear_regression.py
 Â Â  â”œâ”€â”€ metrics.py
 Â Â  â”œâ”€â”€ predict
 Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
 Â Â  â”‚Â Â  â”œâ”€â”€ __main__.py
 Â Â  â”‚Â Â  â””â”€â”€ predict.py
 Â Â  â”œâ”€â”€ train
 Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
 Â Â  â”‚Â Â  â”œâ”€â”€ __main__.py
 Â Â  â”‚Â Â  â””â”€â”€ train.py
 Â Â  â””â”€â”€ viz.py
```

*(Bonus : `viz.py` affiche donnÃ©es + droite de rÃ©gression)*
*Les tests E2E vÃ©rifient aussi les **messages dâ€™erreurs exacts** (snapshot) et les **codes de sortie** (0/1/2).*

---

<h2 id="fichiers-de-configuration">ğŸ› ï¸ Fichiers de configuration</h2>

- `pyproject.toml` (Poetry, dÃ©pendances, lint, type check)
  - Groupe optionnel **[tool.poetry.group.viz]** (non installÃ© par dÃ©faut, rÃ©servÃ© au **bonus**)
- `requirements.txt` (fallback sans Poetry)
- `.coveragerc`, `.gitignore`, `Makefile` (raccourcis CI/CD)
- **Note** : `theta.json` est listÃ© dans `.gitignore` â†’ *ne jamais le versionner*.

---

## ğŸ§ª Tests
- PortÃ©e des tests (mandatory) : `train.py`, `predict.py`, `io_utils.py`, CLI, I/O Î¸, stratÃ©gie GD.  
- `viz.py` est **hors** mandatory et **hors pÃ©rimÃ¨tre** des exigences minimales (peut Ãªtre testÃ© si le bonus est activÃ©).

### Unitaire
- Comparaisons float avec `pytest.approx` uniquement (`rtol=1e-2`), jamais `==`.  
- Test dÃ©diÃ© qui Ã©choue si la mise Ã  jour des Î¸ nâ€™est pas **simultanÃ©e** (utilisation de temporaires).  
- Tests robustesse I/O : CSV manquant, colonnes inattendues, valeurs non numÃ©riques, JSON `theta` absent/corrompu.  
- VÃ©rification des **messages dâ€™erreurs et codes retour** (exemples attendus) :  
  - `ERROR: invalid CSV format (expected columns: km,price)` â†’ exit 2  
  - `ERROR: invalid mileage (must be a non-negative number)` â†’ exit 2  
  - `ERROR: theta file not found: <path>` â†’ exit 2  

### End-to-End
- `predict(0)=0` â†’ `train` â†’ `predict(km_csv) â‰ˆ price`.  
- CLI `--help` (exit 0), erreurs dâ€™options (exit â‰  0, message).  
  - EntrÃ©e interactive : prompt si kilomÃ©trage manquant, gestion EOF/pipe.

### Couverture stricte (100 % global + diff + contrÃ´le par fichier)
```bash
pytest -q
coverage run -m pytest
coverage json
coverage report --fail-under=100
coverage html --skip-empty --show-contexts
```

## ğŸ§¾ Codes de sortie & messages dâ€™erreur (contrat â€œdÃ©fenseâ€‘proofâ€)

Les programmes doivent **imprimer ces messages Ã  lâ€™identique sur stderr** et quitter avec le **code indiquÃ©**.

- `ERROR: theta file not found: <path>` â†’ **exit 2**
- `ERROR: invalid CSV format (expected columns: km,price)` â†’ **exit 2**
- `ERROR: invalid mileage (must be a non-negative number)` â†’ **exit 2**

RÃ¨gles gÃ©nÃ©rales :
- **0** : exÃ©cution nominale (train/predict OK).
- **2** : erreur dâ€™usage/entrÃ©e/Iâ€‘O/validation (fichier manquant, CSV invalide, saisie invalide, etc.).
- **1** : erreur interne inattendue (exception non prÃ©vue).

Tests recommandÃ©s :
- Snapshot minimal des messages dâ€™aide (`--help`) et dâ€™erreur (texte essentiel, stable).
- Asserts explicites sur `returncode` (0, 1 ou 2 selon les cas).

âœ… **Objectifs qualitÃ© (mandatory)** :  
- Coverage **100 %** (statements + branches + diff + contrÃ´le fichier).  
- Mutation testing **â‰¥90 %** (scope global mandatory, avec survivants justifiÃ©s).  
- **TolÃ©rance floats stricte** : toujours utiliser `pytest.approx(..., rel=1e-2)` (jamais `==` sur floats).  
- **Test dÃ©diÃ© â€œMAJ simultanÃ©eâ€** : un test Ã©choue explicitement si Î¸â‚€, Î¸â‚ sont mis Ã  jour sÃ©quentiellement (sans temporaires).  
- Tests E2E : `predict(0)=0 â†’ train â†’ predictâ‰ˆcsv`.  
- Tests robustesse I/O : CSV manquant, mal formÃ©, km nÃ©gatif, NaN, EOF/pipe.  
- Tests CLI : `--help`, erreurs dâ€™options â†’ exit â‰  0 avec message clair.  
- Codes retour : 0 succÃ¨s, â‰ 0 Ã©chec.  

---

## ğŸ” QualitÃ© du code
- Formatage & imports : `ruff format`, `isort`.  
- Typage statique : `mypy`.  
- Lint : `ruff check`.  
- CI/CD Ubuntu-only (GitHub Actions).  
- Hooks `pre-commit` pour vÃ©rifier format/lint/tests rapides avant commit.  
---
## ğŸ“š Documentation liÃ©e
- [`AGENTS.md`](./AGENTS.md) â†’ Blueprint complet CI/CD + checklist dÃ©fense-proof.  
- [`ft_linear_regression_checklist_dÃ©fense-proof.txt`](./ft_linear_regression_checklist_dÃ©fense-proof.txt) â†’ QualitÃ© tests & couverture.  
- [`ft_linear_regression_murphy_law.txt`](./ft_linear_regression_murphy_law.txt) â†’ Risques & contre-mesures.  
- Ã‰noncÃ© officiel : [ft_linear_regression.en.subject.pdf](./ft_linear_regression.en.subject.pdf).  
- Le bonus est **cloisonnÃ©** : il ne doit pas interfÃ©rer avec le mandatory ni impacter la CI de base.

---

## ğŸ¨ Visuel clÃ© (bonus)
<p align="center">
  <a href="./docs/assets/plots/regression/etape3_droites_successives.png">
    <img src="./docs/assets/plots/regression/etape3_droites_successives.png" alt="Descente de gradient â€” droites successives" width="760">
  </a>
  <br><em>La pente se met en place itÃ©ration par itÃ©ration (cliquer pour la galerie).</em>
</p>

â¡ï¸ Voir la galerie complÃ¨te : [docs/regression_lineaire.md](./docs/regression_lineaire.md)

---

## ğŸ“Š Bonus : Bande de confiance 95 %

Une analyse pÃ©dagogique pas Ã  pas montre **pourquoi** la bande est
Ã©troite au centre et large aux extrÃªmes.

<p align="center">
  <img src="./docs/assets/plots/confiance/fig06_bande_95.png" alt="Bande de confiance 95%" width="600">
  <br><em>Bande de confiance autour de la droite de rÃ©gression (extrait).</em>
</p>

ğŸ‘‰ Voir [docs/confidence_band.md](./docs/confidence_band.md)

---

## ğŸ“– Ressources utilisÃ©es

Les contenus suivants ont Ã©tÃ© essentiels pour comprendre et implÃ©menter la rÃ©gression linÃ©aire et lâ€™algorithme du gradient :

- ğŸ¥ [Playlist YouTube â€” Machine Learning from Scratch](https://www.youtube.com/playlist?list=PLO_fdPEVlfKqUF5BPKjGSh7aV9aBshrpY)  
  SÃ©rie pÃ©dagogique dÃ©taillant les fondements du Machine Learning et la rÃ©gression linÃ©aire.

- ğŸ“„ [WikipÃ©dia â€” Fonction linÃ©aire (analyse)](https://fr.wikipedia.org/wiki/Fonction_lin%C3%A9aire_(analyse))  
  DÃ©finitions et propriÃ©tÃ©s mathÃ©matiques de la fonction linÃ©aire.

- ğŸ“„ [WikipÃ©dia â€” Algorithme du gradient](https://fr.wikipedia.org/wiki/Algorithme_du_gradient)  
  Explication thÃ©orique de la descente de gradient et de ses applications en optimisation.


<h2 id="licence">ğŸ›¡ï¸ Licence</h2>
MIT Â© 2025 â€” raveriss  
